# **Librerias**

# Examen Práctico de Minería de Datos
# Universidad Politécnica de San Luis Potosí
# Curso: Minería de Datos
# Tema: Aprendizaje Supervisado y No Supervisado

# Importar las librerías necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.datasets import load_digits, load_wine
from sklearn.preprocessing import StandardScaler

# Parte 1: Aprendizaje Supervisado
# Dataset: Cargar el dataset de digits
def cargar_dataset_digits():
  return load_digits()

# 1.1. Preprocesamiento de Datos
# Escalar los datos
def escalar_datos(X):
  scalaer = StandardScaler()
  return scalaer.fit_transform(X)

# Dividir los datos en conjuntos de entrenamiento y prueba
def dividir_datos(X, y):
  X_train, X_test, y_train, y_test = train_test_split(X, y)
  return X_train, X_test, y_train, y_test

# 1.2. Entrenamiento del Modelo
# Entrenar un modelo de Regresión Logística con 500 iteraciones máximo.
def entrenar_modelo_logistico(X_train, y_train):
  modelo = LogisticRegression(max_iter=1000)
  modelo.fit(X_train, y_train)
  return modelo

# Realizar predicciones
def realizar_predicciones(modelo, X_test):
  return modelo.predict(X_test)

# 1.3. Evaluación del Modelo
# Realizar predicciones y evaluar el modelo
def evaluar_modelo(modelo, X_test, y_test):
  y_pred = modelo.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)
  conf_matrix = confusion_matrix(y_test, y_pred)
  class_report = classification_report(y_test, y_pred)
  return accuracy, conf_matrix, class_report

# Ejecución del examen
# Parte 1: Aprendizaje Supervisado
def ejecucion_supervisado():
  data = cargar_dataset_digits()
  scaler = escalar_datos(data.data)
  X_train, X_test, y_train, y_test = dividir_datos(scaler, data.target)
  modelo = entrenar_modelo_logistico(X_train, y_train)
  y_pred = realizar_predicciones(modelo, X_test)
  accuracy, conf_matrix, class_report = evaluar_modelo(modelo, X_test, y_test)

ejecucion_supervisado()

# Parte 2: Aprendizaje No Supervisado
# Dataset: Cargar el dataset de wine
def cargar_dataset_wine():
  return load_wine()

# 2.1. Preprocesamiento de Datos
# Normalizar los datos
def normalizar_datos(X):
  normalized_data = (X - np.mean(X, axis=0)) / np.std(X, axis=0)
  return normalized_data

# 2.2. Entrenamiento del Modelo
# Entrenar un modelo de K-Means
def entrenar_modelo_kmeans(X, n_clusters=3):
  kmeans = KMeans(n_clusters=n_clusters, random_state=42)
  kmeans.fit(X)
  return kmeans

# 2.3. Evaluación del Modelo
# Asignar etiquetas a los datos
def asignar_etiquetas(modelo, X):
  labels = modelo.predict(X)
  return labels

# Visualizar los clusters
def visualizar_clusters(X, labels):
  plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
  plt.xlabel('Feature 1')
  plt.ylabel('Feature 2')
  plt.title('Clusters')
  plt.show()


# Parte 2: Aprendizaje No Supervisado
def ejecucion_no_supervisado():
  data = cargar_dataset_wine()
  normalized_data = normalizar_datos(data.data)
  modelo = entrenar_modelo_kmeans(normalized_data)
  labels = asignar_etiquetas(modelo, normalized_data)
  visualizar_clusters(normalized_data, labels)

ejecucion_no_supervisado()

# -*- coding: utf-8 -*-
"""ExamenMineriaDeDatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gADyqq4QttH8KDzgHi0bBEm_EZzXM5zW

# **Librerias**
"""

# Examen Práctico de Minería de Datos
# Universidad Politécnica de San Luis Potosí
# Curso: Minería de Datos
# Tema: Aprendizaje Supervisado y No Supervisado

# Importar las librerías necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.datasets import load_digits, load_wine
from sklearn.preprocessing import StandardScaler

# Parte 1: Aprendizaje Supervisado
# Dataset: Cargar el dataset de digits
def cargar_dataset_digits():
  return load_digits()

# 1.1. Preprocesamiento de Datos
# Escalar los datos
def escalar_datos(X):
  scalaer = StandardScaler()
  return scalaer.fit_transform(X)

# Dividir los datos en conjuntos de entrenamiento y prueba
def dividir_datos(X, y):
  print("X: ", X)
  print("y: ", y)

  X_train, X_test, y_train, y_test = train_test_split(X, y)
  return X_train, X_test, y_train, y_test

# 1.2. Entrenamiento del Modelo
# Entrenar un modelo de Regresión Logística con 500 iteraciones máximo.
def entrenar_modelo_logistico(X_train, y_train):
  modelo = LogisticRegression(max_iter=1000)
  modelo.fit(X_train, y_train)
  return modelo

# Realizar predicciones
def realizar_predicciones(modelo, X_test):
  return modelo.predict(X_test)

# 1.3. Evaluación del Modelo
# Realizar predicciones y evaluar el modelo
def evaluar_modelo(modelo, X_test, y_test):
  y_pred = modelo.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)
  conf_matrix = confusion_matrix(y_test, y_pred)
  class_report = classification_report(y_test, y_pred)
  return accuracy, conf_matrix, class_report

# Ejecución del examen
# Parte 1: Aprendizaje Supervisado
def ejecucion_supervisado():
  data = cargar_dataset_digits()
  scaler = escalar_datos(data.data)
  X_train, X_test, y_train, y_test = dividir_datos(scaler, data.target)
  modelo = entrenar_modelo_logistico(X_train, y_train)
  y_pred = realizar_predicciones(modelo, X_test)
  accuracy, conf_matrix, class_report = evaluar_modelo(modelo, X_test, y_test)

ejecucion_supervisado()

# Parte 2: Aprendizaje No Supervisado
# Dataset: Cargar el dataset de wine
def cargar_dataset_wine():
  return load_wine()

# 2.1. Preprocesamiento de Datos
# Normalizar los datos
def normalizar_datos(X):
  normalized_data = (X - np.mean(X, axis=0)) / np.std(X, axis=0)
  return normalized_data

# 2.2. Entrenamiento del Modelo
# Entrenar un modelo de K-Means
def entrenar_modelo_kmeans(X, n_clusters=3):
  kmeans = KMeans(n_clusters=n_clusters, random_state=42)
  kmeans.fit(X)
  return kmeans

# 2.3. Evaluación del Modelo
# Asignar etiquetas a los datos
def asignar_etiquetas(modelo, X):
  labels = modelo.predict(X)
  return labels

# Visualizar los clusters
def visualizar_clusters(X, labels):
  plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
  plt.xlabel('Feature 1')
  plt.ylabel('Feature 2')
  plt.title('Clusters')
  plt.show()


# Parte 2: Aprendizaje No Supervisado
def ejecucion_no_supervisado():
  data = cargar_dataset_wine()
  normalized_data = normalizar_datos(data.data)
  modelo = entrenar_modelo_kmeans(normalized_data)
  labels = asignar_etiquetas(modelo, normalized_data)
  visualizar_clusters(normalized_data, labels)

ejecucion_no_supervisado()
